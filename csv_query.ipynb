{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0390b30b-2ff2-4807-afbf-914229488bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import LlamaCpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e84b0bd0-c267-403e-a019-67140c6ebfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17dd4eb0-7e75-4b11-921e-2260dba99cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc7c0326-feac-49e5-bea4-b23ce1e16571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    return LlamaCpp(\n",
    "        model_path=\"C:/Users/thegh/Python Projects/Ai Models/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf\",\n",
    "        n_gpu_layers=30,\n",
    "        n_ctx=5000,\n",
    "        f16_kv=True,\n",
    "        max_tokens=5000,\n",
    "        temperature=0.1,\n",
    "        streaming=True,\n",
    "        verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "961e2b16-21d7-4e08-9f39-274819d13251",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 33 key-value pairs and 292 tensors from C:/Users/thegh/Python Projects/Ai Models/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Meta Llama 3.1 8B Instruct\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = Instruct\n",
      "llama_model_loader: - kv   4:                           general.basename str              = Meta-Llama-3.1\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = 8B\n",
      "llama_model_loader: - kv   6:                            general.license str              = llama3.1\n",
      "llama_model_loader: - kv   7:                               general.tags arr[str,6]       = [\"facebook\", \"meta\", \"pytorch\", \"llam...\n",
      "llama_model_loader: - kv   8:                          general.languages arr[str,8]       = [\"en\", \"de\", \"fr\", \"it\", \"pt\", \"hi\", ...\n",
      "llama_model_loader: - kv   9:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv  10:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv  11:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv  12:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv  13:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv  14:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  15:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  16:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  17:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  18:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  23:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  24:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  27:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
      "llama_model_loader: - kv  28:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  29:                      quantize.imatrix.file str              = /models_out/Meta-Llama-3.1-8B-Instruc...\n",
      "llama_model_loader: - kv  30:                   quantize.imatrix.dataset str              = /training_dir/calibration_datav3.txt\n",
      "llama_model_loader: - kv  31:             quantize.imatrix.entries_count i32              = 224\n",
      "llama_model_loader: - kv  32:              quantize.imatrix.chunks_count i32              = 125\n",
      "llama_model_loader: - type  f32:   66 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens cache size = 256\n",
      "llm_load_vocab: token to piece cache size = 0.7999 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128256\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 131072\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 131072\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 8B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 8.03 B\n",
      "llm_load_print_meta: model size       = 4.58 GiB (4.89 BPW) \n",
      "llm_load_print_meta: general.name     = Meta Llama 3.1 8B Instruct\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: max token length = 256\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n",
      "ggml_cuda_init: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce RTX 3070 Laptop GPU, compute capability 8.6, VMM: yes\n",
      "llm_load_tensors: ggml ctx size =    0.27 MiB\n",
      "llm_load_tensors: offloading 30 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 30/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  4685.30 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  3727.51 MiB\n",
      "........................................................................................\n",
      "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
      "llama_new_context_with_model: n_ctx      = 5024\n",
      "llama_new_context_with_model: n_batch    = 32\n",
      "llama_new_context_with_model: n_ubatch   = 32\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:  CUDA_Host KV buffer size =    39.25 MiB\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =   588.75 MiB\n",
      "llama_new_context_with_model: KV self size  =  628.00 MiB, K (f16):  314.00 MiB, V (f16):  314.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   427.13 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =     1.11 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 30\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.name': 'Meta Llama 3.1 8B Instruct', 'general.architecture': 'llama', 'general.type': 'model', 'llama.block_count': '32', 'general.basename': 'Meta-Llama-3.1', 'general.finetune': 'Instruct', 'general.size_label': '8B', 'general.license': 'llama3.1', 'llama.context_length': '131072', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '128009', 'general.file_type': '15', 'llama.attention.head_count_kv': '8', 'llama.rope.freq_base': '500000.000000', 'quantize.imatrix.entries_count': '224', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.vocab_size': '128256', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.model': 'gpt2', 'tokenizer.ggml.pre': 'llama-bpe', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '128000', 'tokenizer.chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- set date_string = \"26 Jul 2024\" %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message + builtin tools #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if builtin_tools is defined or tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{%- if builtin_tools is defined %}\\n    {{- \"Tools: \" + builtin_tools | reject(\\'equalto\\', \\'code_interpreter\\') | join(\", \") + \"\\\\n\\\\n\"}}\\n{%- endif %}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] | trim + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\\n            {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\\n                {{- arg_name + \\'=\"\\' + arg_val + \\'\"\\' }}\\n                {%- if not loop.last %}\\n                    {{- \", \" }}\\n                {%- endif %}\\n                {%- endfor %}\\n            {{- \")\" }}\\n        {%- else  %}\\n            {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n            {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n            {{- \\'\"parameters\": \\' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \"}\" }}\\n        {%- endif %}\\n        {%- if builtin_tools is defined %}\\n            {#- This means we\\'re in ipython mode #}\\n            {{- \"<|eom_id|>\" }}\\n        {%- else %}\\n            {{- \"<|eot_id|>\" }}\\n        {%- endif %}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n', 'quantize.imatrix.chunks_count': '125', 'quantize.imatrix.file': '/models_out/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct.imatrix', 'quantize.imatrix.dataset': '/training_dir/calibration_datav3.txt'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {{- bos_token }}\n",
      "{%- if custom_tools is defined %}\n",
      "    {%- set tools = custom_tools %}\n",
      "{%- endif %}\n",
      "{%- if not tools_in_user_message is defined %}\n",
      "    {%- set tools_in_user_message = true %}\n",
      "{%- endif %}\n",
      "{%- if not date_string is defined %}\n",
      "    {%- set date_string = \"26 Jul 2024\" %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
      "{%- if messages[0]['role'] == 'system' %}\n",
      "    {%- set system_message = messages[0]['content']|trim %}\n",
      "    {%- set messages = messages[1:] %}\n",
      "{%- else %}\n",
      "    {%- set system_message = \"\" %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- System message + builtin tools #}\n",
      "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
      "{%- if builtin_tools is defined or tools is not none %}\n",
      "    {{- \"Environment: ipython\\n\" }}\n",
      "{%- endif %}\n",
      "{%- if builtin_tools is defined %}\n",
      "    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\\n\\n\"}}\n",
      "{%- endif %}\n",
      "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
      "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
      "{%- if tools is not none and not tools_in_user_message %}\n",
      "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "{%- endif %}\n",
      "{{- system_message }}\n",
      "{{- \"<|eot_id|>\" }}\n",
      "\n",
      "{#- Custom tools are passed in a user message with some extra guidance #}\n",
      "{%- if tools_in_user_message and not tools is none %}\n",
      "    {#- Extract the first user message so we can plug it in here #}\n",
      "    {%- if messages | length != 0 %}\n",
      "        {%- set first_user_message = messages[0]['content']|trim %}\n",
      "        {%- set messages = messages[1:] %}\n",
      "    {%- else %}\n",
      "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
      "{%- endif %}\n",
      "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
      "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
      "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "    {{- first_user_message + \"<|eot_id|>\"}}\n",
      "{%- endif %}\n",
      "\n",
      "{%- for message in messages %}\n",
      "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
      "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
      "    {%- elif 'tool_calls' in message %}\n",
      "        {%- if not message.tool_calls|length == 1 %}\n",
      "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
      "        {%- endif %}\n",
      "        {%- set tool_call = message.tool_calls[0].function %}\n",
      "        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n",
      "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n",
      "            {%- for arg_name, arg_val in tool_call.arguments | items %}\n",
      "                {{- arg_name + '=\"' + arg_val + '\"' }}\n",
      "                {%- if not loop.last %}\n",
      "                    {{- \", \" }}\n",
      "                {%- endif %}\n",
      "                {%- endfor %}\n",
      "            {{- \")\" }}\n",
      "        {%- else  %}\n",
      "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
      "            {{- '\"parameters\": ' }}\n",
      "            {{- tool_call.arguments | tojson }}\n",
      "            {{- \"}\" }}\n",
      "        {%- endif %}\n",
      "        {%- if builtin_tools is defined %}\n",
      "            {#- This means we're in ipython mode #}\n",
      "            {{- \"<|eom_id|>\" }}\n",
      "        {%- else %}\n",
      "            {{- \"<|eot_id|>\" }}\n",
      "        {%- endif %}\n",
      "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
      "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
      "        {%- if message.content is mapping or message.content is iterable %}\n",
      "            {{- message.content | tojson }}\n",
      "        {%- else %}\n",
      "            {{- message.content }}\n",
      "        {%- endif %}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "Using chat eos_token: <|eot_id|>\n",
      "Using chat bos_token: <|begin_of_text|>\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "llm = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d48f17c-1344-4d9d-8240-e9b3b45e14d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt):\n",
    "    return llm.stream(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0a4e237c-92d1-4615-ad90-0b5e999ce84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User: عاوز اعرف كل السيارات اللى عندها horsepower-binned يكون medium\n"
     ]
    }
   ],
   "source": [
    "user_input = input(\"User:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3fca7f55-5605-43fa-9ab3-8579dbe2eeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = GoogleTranslator(source='auto', target='en').translate(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "082e04fc-e235-4147-9e2f-ee5d54b1b509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to know all the cars that have medium horsepower-binned'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "72ac4921-2ff4-497f-be3f-abb27aab13df",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = (\n",
    "        \"Convert the following natural language query into a pandas query expression:\\n\\n\"\n",
    "        f\"{user_input}\\n\\n\"\n",
    "        \"Note: Use the correct pandas syntax, use column names directly. Don't Write anything else.\\n\\n\"\n",
    "        \"Pandas Query:\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7aee7bd0-37ac-49b6-9ff9-5b9cb6f0d37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine chat history and user question\n",
    "full_prompt = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "            Cutting Knowledge Date: December 2023\n",
    "            Today Date: 23 Jul 2024\n",
    "            Answer like this :\n",
    "            User: What if I have 6300, which car can I buy?\n",
    "            Assistant: price <= 6300.\n",
    "            User : How many alfa-romero cars do you have?\n",
    "            Assistant: make == 'alfa-romero'.\n",
    "            Just Fucking give me as what I showed you in Assistant response, Don't Give me anything else from you.\n",
    "            {prompt}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4b323b82-6bf1-4843-87e2-f1ae98eff2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thegh\\anaconda3\\envs\\alaa_ai_env\\Lib\\site-packages\\llama_cpp\\llama.py:1129: RuntimeWarning: Detected duplicate leading \"<|begin_of_text|>\" in prompt, this will likely reduce response quality, consider removing it...\n",
      "  warnings.warn(\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I want to know all the cars that have medium horsepower-binned\n",
      "             Pd = pd.DataFrame({'make': ['alfa-romero', 'audi', 'bmw'], \n",
      " 'model': ['giulia', 'a4', 'm3'], \n",
      " 'year': [1962, 1990, 1986], \n",
      " 'hp': [232, 190, 240]})\n",
      "\n",
      "\n",
      "            Pandas Query: \n",
      "            (pd['make'] == 'alfa-romero') & (pd['hp'] >= 200) & (pd['hp'] <= 300))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1376.84 ms\n",
      "llama_print_timings:      sample time =      68.98 ms /   125 runs   (    0.55 ms per token,  1812.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     873.55 ms /    78 tokens (   11.20 ms per token,    89.29 tokens per second)\n",
      "llama_print_timings:        eval time =    5655.76 ms /   124 runs   (   45.61 ms per token,    21.92 tokens per second)\n",
      "llama_print_timings:       total time =    6844.60 ms /   202 tokens\n"
     ]
    }
   ],
   "source": [
    "response_generator = generate_response(full_prompt)\n",
    "response_text=''\n",
    "for chunk in response_generator:\n",
    "    response_text += chunk\n",
    "    print(chunk , end ='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "49ea1327-b4f4-4a19-895e-73432d7633b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8d321da9-f470-48b2-80df-27288ff69416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" make == 'nissan'\""
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3949b2d7-f34d-4b8d-8bb1-aaf8f74355d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your CSV file\n",
    "df = pd.read_csv('used car pricing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e61f2335-2bb3-41ad-977e-23a842000e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(df, sql_query):\n",
    "    try:\n",
    "        result = df.query(sql_query)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"Error executing query: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4a545eaa-47a8-4179-804e-a5a5556481df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the SQL query\n",
    "result = execute_query(df, sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "df800fe5-aad6-410c-b2f4-38e1a9f1a669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symboling</th>\n",
       "      <th>normalized-losses</th>\n",
       "      <th>make</th>\n",
       "      <th>num-of-doors</th>\n",
       "      <th>body-style</th>\n",
       "      <th>drive-wheels</th>\n",
       "      <th>engine-location</th>\n",
       "      <th>wheel-base</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>...</th>\n",
       "      <th>city-mpg</th>\n",
       "      <th>highway-mpg</th>\n",
       "      <th>price</th>\n",
       "      <th>city-L/100km</th>\n",
       "      <th>highway-L/100km</th>\n",
       "      <th>horsepower-binned</th>\n",
       "      <th>fuel-type-diesel</th>\n",
       "      <th>fuel-type-gas</th>\n",
       "      <th>aspiration-std</th>\n",
       "      <th>aspiration-turbo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>nissan</td>\n",
       "      <td>two</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>0.794330</td>\n",
       "      <td>0.882434</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>5499.0</td>\n",
       "      <td>7.580645</td>\n",
       "      <td>6.351351</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>nissan</td>\n",
       "      <td>two</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>0.794330</td>\n",
       "      <td>0.882434</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>5.222222</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>Low</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>nissan</td>\n",
       "      <td>two</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>0.794330</td>\n",
       "      <td>0.882434</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>6649.0</td>\n",
       "      <td>7.580645</td>\n",
       "      <td>6.351351</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>nissan</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>0.794330</td>\n",
       "      <td>0.882434</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>6849.0</td>\n",
       "      <td>7.580645</td>\n",
       "      <td>6.351351</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>nissan</td>\n",
       "      <td>four</td>\n",
       "      <td>wagon</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>0.817876</td>\n",
       "      <td>0.882434</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>7349.0</td>\n",
       "      <td>7.580645</td>\n",
       "      <td>6.351351</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>nissan</td>\n",
       "      <td>two</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>0.794330</td>\n",
       "      <td>0.882434</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>7299.0</td>\n",
       "      <td>7.580645</td>\n",
       "      <td>6.351351</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>nissan</td>\n",
       "      <td>two</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>0.795771</td>\n",
       "      <td>0.882434</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>7799.0</td>\n",
       "      <td>7.580645</td>\n",
       "      <td>6.351351</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>nissan</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>0.794330</td>\n",
       "      <td>0.882434</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>7499.0</td>\n",
       "      <td>7.580645</td>\n",
       "      <td>6.351351</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>nissan</td>\n",
       "      <td>four</td>\n",
       "      <td>wagon</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>0.817876</td>\n",
       "      <td>0.882434</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>7999.0</td>\n",
       "      <td>7.580645</td>\n",
       "      <td>6.351351</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>nissan</td>\n",
       "      <td>two</td>\n",
       "      <td>hardtop</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>95.1</td>\n",
       "      <td>0.780394</td>\n",
       "      <td>0.882434</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>8249.0</td>\n",
       "      <td>7.580645</td>\n",
       "      <td>6.351351</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>nissan</td>\n",
       "      <td>four</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>97.2</td>\n",
       "      <td>0.833253</td>\n",
       "      <td>0.901798</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>8949.0</td>\n",
       "      <td>8.703704</td>\n",
       "      <td>6.911765</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>nissan</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>97.2</td>\n",
       "      <td>0.833253</td>\n",
       "      <td>0.901798</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>9549.0</td>\n",
       "      <td>8.703704</td>\n",
       "      <td>6.911765</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>nissan</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>100.4</td>\n",
       "      <td>0.873138</td>\n",
       "      <td>0.919779</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>13499.0</td>\n",
       "      <td>13.823529</td>\n",
       "      <td>10.681818</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>nissan</td>\n",
       "      <td>four</td>\n",
       "      <td>wagon</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>100.4</td>\n",
       "      <td>0.887074</td>\n",
       "      <td>0.919779</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>14399.0</td>\n",
       "      <td>13.823529</td>\n",
       "      <td>10.681818</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>nissan</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>100.4</td>\n",
       "      <td>0.887074</td>\n",
       "      <td>0.919779</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>13499.0</td>\n",
       "      <td>12.368421</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>3</td>\n",
       "      <td>194</td>\n",
       "      <td>nissan</td>\n",
       "      <td>two</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>91.3</td>\n",
       "      <td>0.820279</td>\n",
       "      <td>0.939142</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>17199.0</td>\n",
       "      <td>12.368421</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>3</td>\n",
       "      <td>194</td>\n",
       "      <td>nissan</td>\n",
       "      <td>two</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>91.3</td>\n",
       "      <td>0.820279</td>\n",
       "      <td>0.939142</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>19699.0</td>\n",
       "      <td>13.823529</td>\n",
       "      <td>10.217391</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1</td>\n",
       "      <td>231</td>\n",
       "      <td>nissan</td>\n",
       "      <td>two</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.2</td>\n",
       "      <td>0.857761</td>\n",
       "      <td>0.939142</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>18399.0</td>\n",
       "      <td>12.368421</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     symboling  normalized-losses    make num-of-doors body-style  \\\n",
       "88           1                128  nissan          two      sedan   \n",
       "89           1                128  nissan          two      sedan   \n",
       "90           1                128  nissan          two      sedan   \n",
       "91           1                122  nissan         four      sedan   \n",
       "92           1                103  nissan         four      wagon   \n",
       "93           1                128  nissan          two      sedan   \n",
       "94           1                128  nissan          two  hatchback   \n",
       "95           1                122  nissan         four      sedan   \n",
       "96           1                103  nissan         four      wagon   \n",
       "97           2                168  nissan          two    hardtop   \n",
       "98           0                106  nissan         four  hatchback   \n",
       "99           0                106  nissan         four      sedan   \n",
       "100          0                128  nissan         four      sedan   \n",
       "101          0                108  nissan         four      wagon   \n",
       "102          0                108  nissan         four      sedan   \n",
       "103          3                194  nissan          two  hatchback   \n",
       "104          3                194  nissan          two  hatchback   \n",
       "105          1                231  nissan          two  hatchback   \n",
       "\n",
       "    drive-wheels engine-location  wheel-base    length     width  ...  \\\n",
       "88           fwd           front        94.5  0.794330  0.882434  ...   \n",
       "89           fwd           front        94.5  0.794330  0.882434  ...   \n",
       "90           fwd           front        94.5  0.794330  0.882434  ...   \n",
       "91           fwd           front        94.5  0.794330  0.882434  ...   \n",
       "92           fwd           front        94.5  0.817876  0.882434  ...   \n",
       "93           fwd           front        94.5  0.794330  0.882434  ...   \n",
       "94           fwd           front        94.5  0.795771  0.882434  ...   \n",
       "95           fwd           front        94.5  0.794330  0.882434  ...   \n",
       "96           fwd           front        94.5  0.817876  0.882434  ...   \n",
       "97           fwd           front        95.1  0.780394  0.882434  ...   \n",
       "98           fwd           front        97.2  0.833253  0.901798  ...   \n",
       "99           fwd           front        97.2  0.833253  0.901798  ...   \n",
       "100          fwd           front       100.4  0.873138  0.919779  ...   \n",
       "101          fwd           front       100.4  0.887074  0.919779  ...   \n",
       "102          fwd           front       100.4  0.887074  0.919779  ...   \n",
       "103          rwd           front        91.3  0.820279  0.939142  ...   \n",
       "104          rwd           front        91.3  0.820279  0.939142  ...   \n",
       "105          rwd           front        99.2  0.857761  0.939142  ...   \n",
       "\n",
       "     city-mpg  highway-mpg    price city-L/100km  highway-L/100km  \\\n",
       "88         31           37   5499.0     7.580645         6.351351   \n",
       "89         45           50   7099.0     5.222222         4.700000   \n",
       "90         31           37   6649.0     7.580645         6.351351   \n",
       "91         31           37   6849.0     7.580645         6.351351   \n",
       "92         31           37   7349.0     7.580645         6.351351   \n",
       "93         31           37   7299.0     7.580645         6.351351   \n",
       "94         31           37   7799.0     7.580645         6.351351   \n",
       "95         31           37   7499.0     7.580645         6.351351   \n",
       "96         31           37   7999.0     7.580645         6.351351   \n",
       "97         31           37   8249.0     7.580645         6.351351   \n",
       "98         27           34   8949.0     8.703704         6.911765   \n",
       "99         27           34   9549.0     8.703704         6.911765   \n",
       "100        17           22  13499.0    13.823529        10.681818   \n",
       "101        17           22  14399.0    13.823529        10.681818   \n",
       "102        19           25  13499.0    12.368421         9.400000   \n",
       "103        19           25  17199.0    12.368421         9.400000   \n",
       "104        17           23  19699.0    13.823529        10.217391   \n",
       "105        19           25  18399.0    12.368421         9.400000   \n",
       "\n",
       "    horsepower-binned  fuel-type-diesel  fuel-type-gas  aspiration-std  \\\n",
       "88                Low             False           True            True   \n",
       "89                Low              True          False            True   \n",
       "90                Low             False           True            True   \n",
       "91                Low             False           True            True   \n",
       "92                Low             False           True            True   \n",
       "93                Low             False           True            True   \n",
       "94                Low             False           True            True   \n",
       "95                Low             False           True            True   \n",
       "96                Low             False           True            True   \n",
       "97                Low             False           True            True   \n",
       "98                Low             False           True            True   \n",
       "99                Low             False           True            True   \n",
       "100            Medium             False           True            True   \n",
       "101            Medium             False           True            True   \n",
       "102            Medium             False           True            True   \n",
       "103            Medium             False           True            True   \n",
       "104            Medium             False           True           False   \n",
       "105            Medium             False           True            True   \n",
       "\n",
       "     aspiration-turbo  \n",
       "88              False  \n",
       "89              False  \n",
       "90              False  \n",
       "91              False  \n",
       "92              False  \n",
       "93              False  \n",
       "94              False  \n",
       "95              False  \n",
       "96              False  \n",
       "97              False  \n",
       "98              False  \n",
       "99              False  \n",
       "100             False  \n",
       "101             False  \n",
       "102             False  \n",
       "103             False  \n",
       "104              True  \n",
       "105             False  \n",
       "\n",
       "[18 rows x 31 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c3f78f9e-68e3-4181-8040-355a7d31fb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = execute_query(df, \"horsepower_binned == 'nissan'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cb82f40a-c755-4387-b388-780470a43bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Error executing query: name 'horsepower_binned' is not defined\""
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82abd29b-e2c1-4331-80dc-760597cfecf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
